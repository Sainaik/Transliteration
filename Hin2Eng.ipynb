{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hin2Eng.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7fWR0bGH-4HJ","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import numpy as np\n","\n","# Instantiates the device to be used as GPU/CPU based on availability\n","device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Visualization tools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import clear_output\n","\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5e1I7WTg_DA8","colab_type":"code","outputId":"c74a421b-c829-4be9-c866-c189a42c0efd","executionInfo":{"status":"ok","timestamp":1578068201903,"user_tz":-330,"elapsed":10539,"user":{"displayName":"Sai kumar Naik","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn_bYHBDuIBCf37TYJxSwsW4A0apG2MkZVnHKvqfQ=s64","userId":"17087233214666693558"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","pad_char = '-PAD-'\n","\n","eng_alpha2index = {pad_char: 0}\n","for index, alpha in enumerate(eng_alphabets):\n","    eng_alpha2index[alpha] = index+1\n","\n","print(eng_alpha2index)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3k5GyfWrCLox","colab_type":"code","outputId":"19350690-314f-46e2-9109-81798d6590e8","executionInfo":{"status":"ok","timestamp":1578068205981,"user_tz":-330,"elapsed":4051,"user":{"displayName":"Sai kumar Naik","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn_bYHBDuIBCf37TYJxSwsW4A0apG2MkZVnHKvqfQ=s64","userId":"17087233214666693558"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","eng_alpha = {0:'_'}\n","for i in range(0,26):\n","   eng_alpha[i+1]=eng_alphabets[i]\n","\n","print(eng_alpha)   \n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{0: '_', 1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E', 6: 'F', 7: 'G', 8: 'H', 9: 'I', 10: 'J', 11: 'K', 12: 'L', 13: 'M', 14: 'N', 15: 'O', 16: 'P', 17: 'Q', 18: 'R', 19: 'S', 20: 'T', 21: 'U', 22: 'V', 23: 'W', 24: 'X', 25: 'Y', 26: 'Z'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tvKjJky1_G9Q","colab_type":"code","outputId":"1ffb4eb5-2530-4555-d5ac-51b9789f31b2","executionInfo":{"status":"ok","timestamp":1578068212867,"user_tz":-330,"elapsed":9984,"user":{"displayName":"Sai kumar Naik","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn_bYHBDuIBCf37TYJxSwsW4A0apG2MkZVnHKvqfQ=s64","userId":"17087233214666693558"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n","\n","hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n","hindi_alphabet_size = len(hindi_alphabets)\n","\n","hindi_alpha2index = {pad_char: 0}\n","for index, alpha in enumerate(hindi_alphabets):\n","    hindi_alpha2index[alpha] = index+1\n","\n","print(hindi_alpha2index)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oSsutBT0_Ki6","colab_type":"code","colab":{}},"source":["import re\n","non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n","\n","# Remove all English non-letters\n","def cleanEnglishVocab(line):\n","    line = line.replace('-', ' ').replace(',', ' ').upper()\n","    line = non_eng_letters_regex.sub('', line)\n","    return line.split()\n","\n","# Remove all Hindi non-letters\n","def cleanHindiVocab(line):\n","    line = line.replace('-', ' ').replace(',', ' ')\n","    cleaned_line = ''\n","    for char in line:\n","        if char in hindi_alpha2index or char == ' ':\n","            cleaned_line += char\n","    return cleaned_line.split()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AfjPHuQH_PHg","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset\n","import xml.etree.ElementTree as ET\n","\n","class TransliterationDataLoader(Dataset):\n","    def __init__(self, filename):\n","        self.eng_words, self.hindi_words = self.readXmlDataset(filename,cleanHindiVocab)   # cleanHindiVocab\n","        self.shuffle_indices = list(range(len(self.eng_words)))\n","        random.shuffle(self.shuffle_indices)\n","        self.shuffle_start_index = 0\n","        \n","    def __len__(self):\n","        return len(self.eng_words)\n","    \n","    def __getitem__(self, idx):\n","        return self.eng_words[idx], self.hindi_words[idx]\n","    \n","    def readXmlDataset(self, filename, lang_vocab_cleaner):\n","        transliterationCorpus = ET.parse(filename).getroot()\n","        lang1_words = []\n","        lang2_words = []\n","\n","        for line in transliterationCorpus:\n","            wordlist1 = cleanEnglishVocab(line[0].text)\n","            wordlist2 = lang_vocab_cleaner(line[1].text)\n","\n","            # Skip noisy data\n","            if len(wordlist1) != len(wordlist2):\n","                print('Skipping: ', line[0].text, ' - ', line[1].text)\n","                continue\n","\n","            for word in wordlist1:\n","                lang1_words.append(word)\n","            for word in wordlist2:\n","                lang2_words.append(word)\n","\n","        return lang1_words, lang2_words\n","    \n","    def get_random_sample(self):\n","        return self.__getitem__(np.random.randint(len(self.eng_words)))\n","    \n","    def get_batch_from_array(self, batch_size, array):\n","        end = self.shuffle_start_index + batch_size\n","        batch = []\n","        if end >= len(self.eng_words):\n","            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n","            end = len(self.eng_words)\n","        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n","    \n","    def get_batch(self, batch_size, postprocess = True):\n","        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n","        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n","        self.shuffle_start_index += batch_size + 1\n","        \n","        # Reshuffle if 1 epoch is complete\n","        if self.shuffle_start_index >= len(self.eng_words):\n","            random.shuffle(self.shuffle_indices)\n","            self.shuffle_start_index = 0\n","            \n","        return eng_batch, hindi_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPBDKEMI_cUO","colab_type":"code","colab":{}},"source":["train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n","test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"25OkZYpj_fci","colab_type":"code","outputId":"36281c27-bf7b-44a5-ff24-7eeeb5e79e34","executionInfo":{"status":"ok","timestamp":1577975491030,"user_tz":-330,"elapsed":4385,"user":{"displayName":"Sai kumar Naik","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn_bYHBDuIBCf37TYJxSwsW4A0apG2MkZVnHKvqfQ=s64","userId":"17087233214666693558"}},"colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["print(\"Train Set Size:\\t\", len(train_data))\n","print(\"Test Set Size:\\t\", len(test_data))\n","\n","print('\\nSample data from train-set:')\n","for i in range(10):\n","    eng, hindi = train_data.get_random_sample()\n","    print(eng + ' - ' + hindi)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Set Size:\t 20641\n","Test Set Size:\t 1000\n","\n","Sample data from train-set:\n","PHILIPPINE - फिलीपीन\n","REKHA - रेखा\n","CONVENT - कॉंन्वेंट\n","NATIONAL - नेशनल\n","MAURO - मौरो\n","MALIKAA - मलिका\n","SUMITRA - सुमित्रा\n","AKALGADIYA - अकालगड़िया\n","MUSEUM - म्युज़ियम\n","EXFO - ईएक्सएफ़ओ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PbGGyLRf_nOn","colab_type":"code","colab":{}},"source":["def word_rep(word, letter2index, device = 'cpu'):\n","    #print('word', word)\n","    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n","    for letter_index, letter in enumerate(word):\n","        pos = letter2index[letter]\n","        rep[letter_index][0][pos] = 1\n","    pad_pos = letter2index[pad_char]\n","    rep[letter_index+1][0][pad_pos] = 1\n","    return rep\n","\n","def gt_rep(word, letter2index, device = 'cpu'):\n","    #print('gt',word)\n","    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n","    for letter_index, letter in enumerate(word):\n","        pos = letter2index[letter]\n","        gt_rep[letter_index][0] = pos\n","    gt_rep[letter_index+1][0] = letter2index[pad_char]\n","    return gt_rep"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNxEi_uE_qvG","colab_type":"code","colab":{}},"source":["eng, hindi = train_data.get_random_sample()\n","eng_gt = word_rep(eng, eng_alpha2index)\n","print(eng, eng_gt)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dm-gz9VK_uo7","colab_type":"code","colab":{}},"source":["hindi_rep = word_rep(hindi, hindi_alpha2index)\n","print(hindi, hindi_rep)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"leI4QhLsCXE6","colab_type":"code","colab":{}},"source":["MAX_OUTPUT_CHARS = 30\n","class Transliteration_EncoderDecoder_Attention(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n","        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n","        \n","        # delete it\n","        #print(\"Constructor is called\")\n","\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        \n","        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n","        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n","        \n","        self.h2o = nn.Linear(hidden_size, output_size)  #hidden to out\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        \n","        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size, 1)\n","        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n","        \n","        self.verbose = verbose\n","        \n","    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n","        \n","\n","        print(\"forward is called\") # delete it\n","        # encoder\n","        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n","        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n","        \n","        if self.verbose:\n","            print('Encoder output', encoder_outputs.shape)\n","        \n","        # decoder\n","        decoder_state = hidden\n","        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n","        \n","        outputs = []\n","        U = self.U(encoder_outputs)\n","        \n","        if self.verbose:\n","            print('Decoder state', decoder_state.shape)\n","            print('Decoder intermediate input', decoder_input.shape)\n","            print('U * Encoder output', U.shape)\n","        print(type(decoder_state))\n","        return\n","        for i in range(max_output_chars):\n","            \n","            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n","            V = self.attn(torch.tanh(U + W))\n","            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n","            \n","            if self.verbose:\n","                print('W * Decoder state', W.shape)\n","                print('V', V.shape)\n","                print('Attn', attn_weights.shape)\n","            \n","            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","            \n","            embedding = self.out2hidden(decoder_input)\n","            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n","            \n","            if self.verbose:\n","                print('Attn LC', attn_applied.shape)\n","                print('Decoder input', decoder_input.shape)\n","                \n","            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n","            \n","            if self.verbose:\n","                print('Decoder intermediate output', out.shape)\n","                \n","            out = self.h2o(decoder_state)\n","            out = self.softmax(out)\n","            outputs.append(out.view(1, -1))\n","            \n","            if self.verbose:\n","                print('Decoder output', out.shape)\n","                self.verbose = False\n","            \n","            max_idx = torch.argmax(out, 2, keepdim=True)\n","            if not ground_truth is None:\n","                max_idx = ground_truth[i].reshape(1, 1, 1)\n","            one_hot = torch.zeros(out.shape, device=device)\n","            one_hot.scatter_(2, max_idx, 1) \n","            \n","            decoder_input = one_hot.detach()\n","            \n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8wh1kimEeX6","colab_type":"text"},"source":["## Hindi to English"]},{"cell_type":"code","metadata":{"id":"pmEttRRiEYuo","colab_type":"code","colab":{}},"source":["net_attn1 = Transliteration_EncoderDecoder_Attention(len(hindi_alpha2index), 512, len(eng_alpha2index), verbose=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGHbI1IHC40v","colab_type":"code","colab":{}},"source":["def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n","    #print('im called trainbatch')\n","    net.train().to(device)\n","    opt.zero_grad()\n","    eng_batch , hindi_batch = train_data.get_batch(batch_size)\n","    total_loss = 0\n","    for i in range(batch_size):\n","      input = word_rep(hindi_batch[i], hindi_alpha2index, device)\n","      gt = gt_rep(eng_batch[i], eng_alpha2index, device)\n","      outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n","      \n","        \n","      for index, output in enumerate(outputs):\n","          loss = criterion(output, gt[index]) / batch_size\n","          loss.backward(retain_graph = True)\n","          total_loss += loss\n","        \n","    opt.step()\n","    return total_loss/batch_size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvEaxAiwC7tm","colab_type":"code","colab":{}},"source":["def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n","    \n","    net = net.to(device)\n","    criterion = nn.NLLLoss(ignore_index = -1)\n","    opt = optim.Adam(net.parameters(), lr=lr)\n","    teacher_force_upto = n_batches//3  # (returns integer value)\n","    \n","    loss_arr = np.zeros(n_batches + 1)\n","    \n","    for i in range(n_batches):\n","        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n","        \n","        if i%display_freq == display_freq-1:\n","            clear_output(wait=True)\n","            \n","            print('Iteration', i, 'Loss', loss_arr[i])\n","            plt.figure()\n","            plt.plot(loss_arr[1:i], '-*')\n","            plt.xlabel('Iteration')\n","            plt.ylabel('Loss')\n","            plt.show()\n","            print('\\n\\n')\n","            \n","    torch.save(net, 'model.pt')\n","    return loss_arr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NBMTInmDC6t","colab_type":"code","colab":{}},"source":["loss_history = train_setup(net_attn1, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBk0k70BomyG","colab_type":"code","colab":{}},"source":["def infer(net, word ,max_output_chars,device):\n","\n","    net.eval().to(device) # We are not training the model\n","\n","    word_ohe = word_rep(word, hindi_alpha2index) # Convert input to  #combination of one hot vector representation\n","\n","    output = net(word_ohe, max_output_chars)\n","    #print(output)\n","    return output\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-awqSr9oyS1","colab_type":"code","colab":{}},"source":["def calc_accuracy(net, device = 'cpu'):\n","    \n","    #predictions = {}\n","    accuracy = 0\n","    for i in range(len(test_data)):\n","        eng, hindi = test_data[i]\n","        gt = gt_rep(eng, eng_alpha2index, device)\n","        outputs = infer(net, hindi, gt.shape[0], device)\n","        #print(outputs)\n","        # storing the predicted output   \n","        #predictions[hindi]=eng_output\n","        #pred_word = ''\n","        correct = 0\n","        for index, out in enumerate(outputs):\n","            val, indices = out.topk(1)\n","            #print(val,indices)\n","            eng_pos = indices.tolist()[0]\n","            #print(eng_pos)\n","            if eng_pos[0] == gt[index][0]:\n","              correct += 1\n","            #pred_word += eng_alpha[eng_pos[0]]\n","        #predictions[hindi]=pred_word\n","        #print(pred_word)\n","        accuracy += correct/gt.shape[0]\n","    accuracy /= len(test_data)\n","    #print(predictions)\n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRHTsnnGozd6","colab_type":"code","colab":{}},"source":["accuracy_attn = calc_accuracy(net_attn1) * 100\n","print('Acurracy with attention', accuracy_attn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uyFo37qaS5Iq","colab_type":"text"},"source":["## Loading the saved model"]},{"cell_type":"code","metadata":{"id":"0RX4e0R1SPrc","colab_type":"code","colab":{}},"source":["model = torch.load('model.pt')\n","calc_accuracy(model)\n","#print('Acurracy with attention', accuracy_attn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1pwRWrgEN5h","colab_type":"text"},"source":["##Test"]},{"cell_type":"code","metadata":{"id":"4vNH3o9iLC_r","colab_type":"code","colab":{}},"source":["def test(word,model,device='cpu'):\n","    \n","    # calculating the approximate lenth of word\n","    length = 0\n","    for letter in enumerate(word):\n","      length=length+1  \n","    outputs = infer(model,word,(length+2), device)\n","    pred_word = ''\n","    for index, out in enumerate(outputs):\n","      val, indices = out.topk(1)\n","      #print(val,indices)\n","      eng_pos = indices.tolist()[0]\n","      #print(eng_pos)\n","      pred_word += eng_alpha[eng_pos[0]]\n","    return pred_word  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZGCQ3X-MOy7","colab_type":"code","outputId":"2a13fa0f-5f53-49bf-ed8f-99219535dbd1","executionInfo":{"status":"ok","timestamp":1577989236809,"user_tz":-330,"elapsed":1967,"user":{"displayName":"Sai kumar Naik","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn_bYHBDuIBCf37TYJxSwsW4A0apG2MkZVnHKvqfQ=s64","userId":"17087233214666693558"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["word = 'आसान'\n","test_word = test(word,model)\n","print(test_word)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["AASAN_\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"303Ujk1-WIlE","colab_type":"code","outputId":"360c9e30-b20b-4b6d-b9b6-a11251879154","executionInfo":{"status":"ok","timestamp":1577986986535,"user_tz":-330,"elapsed":982,"user":{"displayName":"Sai kumar Naik","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn_bYHBDuIBCf37TYJxSwsW4A0apG2MkZVnHKvqfQ=s64","userId":"17087233214666693558"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(test_data[0][1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["आधी\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FoYwyDqPY8o2","colab_type":"code","colab":{}},"source":["def test(model, device = 'cpu'):\n","  predictions = {}\n","  for i in range(1):\n","        eng, hindi = test_data[i]\n","        #gt = gt_rep(eng, eng_alpha2index, device)\n","        outputs = infer(model, hindi, 6, device)\n","        #print(outputs)\n","        # storing the predicted output   \n","        #predictions[hindi]=eng_output\n","        pred_word = ''\n","        for index, out in enumerate(outputs):\n","            val, indices = out.topk(1)\n","            #print(val,indices)\n","            eng_pos = indices.tolist()[0]\n","            #print(eng_pos)\n","            pred_word += eng_alpha[eng_pos[0]]\n","        predictions[hindi]=pred_word\n","        #print(pred_word)\n","  return predictions"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MQGOyf-s7fnl","colab_type":"text"},"source":["## Playground"]},{"cell_type":"code","metadata":{"id":"tdzBIXIO7iID","colab_type":"code","colab":{}},"source":["\n","class GRU_net(nn.Module):\n","  def __init__(self):\n","    super(GRU_net,self).__init__()\n","    self.gru = nn.GRU(input_size,hidden_size,num_layers);\n","\n"],"execution_count":0,"outputs":[]}]}